{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.632375</td>\n",
       "      <td>7.251936</td>\n",
       "      <td>-17.681072</td>\n",
       "      <td>8.204144</td>\n",
       "      <td>-10.166591</td>\n",
       "      <td>-4.510344</td>\n",
       "      <td>-12.981606</td>\n",
       "      <td>6.783589</td>\n",
       "      <td>-4.659330</td>\n",
       "      <td>-14.924655</td>\n",
       "      <td>...</td>\n",
       "      <td>2.715357</td>\n",
       "      <td>0.695603</td>\n",
       "      <td>-1.138122</td>\n",
       "      <td>0.459442</td>\n",
       "      <td>0.386337</td>\n",
       "      <td>0.522438</td>\n",
       "      <td>-1.416604</td>\n",
       "      <td>-0.488307</td>\n",
       "      <td>0.400490</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.385108</td>\n",
       "      <td>1.217620</td>\n",
       "      <td>-1.953872</td>\n",
       "      <td>2.087076</td>\n",
       "      <td>-1.144225</td>\n",
       "      <td>-0.576888</td>\n",
       "      <td>-2.582865</td>\n",
       "      <td>0.643230</td>\n",
       "      <td>-1.191233</td>\n",
       "      <td>-3.095094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594623</td>\n",
       "      <td>0.372144</td>\n",
       "      <td>-0.310456</td>\n",
       "      <td>-0.624065</td>\n",
       "      <td>0.840216</td>\n",
       "      <td>-0.159452</td>\n",
       "      <td>0.599482</td>\n",
       "      <td>0.288916</td>\n",
       "      <td>-0.321245</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.157678</td>\n",
       "      <td>0.079901</td>\n",
       "      <td>1.790682</td>\n",
       "      <td>-1.968303</td>\n",
       "      <td>-0.589608</td>\n",
       "      <td>0.137942</td>\n",
       "      <td>-0.641184</td>\n",
       "      <td>0.551862</td>\n",
       "      <td>-1.028029</td>\n",
       "      <td>0.331934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482099</td>\n",
       "      <td>1.359236</td>\n",
       "      <td>-0.271784</td>\n",
       "      <td>-0.269525</td>\n",
       "      <td>0.063426</td>\n",
       "      <td>-0.189034</td>\n",
       "      <td>-0.062240</td>\n",
       "      <td>-0.139962</td>\n",
       "      <td>-0.315248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.225537</td>\n",
       "      <td>-0.271419</td>\n",
       "      <td>0.500382</td>\n",
       "      <td>-1.936124</td>\n",
       "      <td>-0.383645</td>\n",
       "      <td>-0.294170</td>\n",
       "      <td>-0.009929</td>\n",
       "      <td>0.088852</td>\n",
       "      <td>-0.790604</td>\n",
       "      <td>0.253379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298460</td>\n",
       "      <td>0.723612</td>\n",
       "      <td>-0.067666</td>\n",
       "      <td>-0.513540</td>\n",
       "      <td>-0.389335</td>\n",
       "      <td>-0.240228</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>0.026852</td>\n",
       "      <td>-0.201302</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.269172</td>\n",
       "      <td>0.444892</td>\n",
       "      <td>0.172031</td>\n",
       "      <td>1.022692</td>\n",
       "      <td>0.015860</td>\n",
       "      <td>-0.732037</td>\n",
       "      <td>0.297024</td>\n",
       "      <td>-0.281962</td>\n",
       "      <td>-0.183246</td>\n",
       "      <td>-0.021727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018769</td>\n",
       "      <td>0.163191</td>\n",
       "      <td>-0.159069</td>\n",
       "      <td>0.072121</td>\n",
       "      <td>0.777835</td>\n",
       "      <td>-0.310421</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>0.019546</td>\n",
       "      <td>-0.332959</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        # V1        V2         V3        V4         V5        V6         V7  \\\n",
       "0 -10.632375  7.251936 -17.681072  8.204144 -10.166591 -4.510344 -12.981606   \n",
       "1   0.385108  1.217620  -1.953872  2.087076  -1.144225 -0.576888  -2.582865   \n",
       "2  -1.157678  0.079901   1.790682 -1.968303  -0.589608  0.137942  -0.641184   \n",
       "3   0.225537 -0.271419   0.500382 -1.936124  -0.383645 -0.294170  -0.009929   \n",
       "4   1.269172  0.444892   0.172031  1.022692   0.015860 -0.732037   0.297024   \n",
       "\n",
       "         V8        V9        V10  ...         V21       V22       V23  \\\n",
       "0  6.783589 -4.659330 -14.924655  ...    2.715357  0.695603 -1.138122   \n",
       "1  0.643230 -1.191233  -3.095094  ...    0.594623  0.372144 -0.310456   \n",
       "2  0.551862 -1.028029   0.331934  ...    0.482099  1.359236 -0.271784   \n",
       "3  0.088852 -0.790604   0.253379  ...    0.298460  0.723612 -0.067666   \n",
       "4 -0.281962 -0.183246  -0.021727  ...    0.018769  0.163191 -0.159069   \n",
       "\n",
       "        V24       V25       V26       V27       V28  normAmount  Class  \n",
       "0  0.459442  0.386337  0.522438 -1.416604 -0.488307    0.400490    1.0  \n",
       "1 -0.624065  0.840216 -0.159452  0.599482  0.288916   -0.321245    1.0  \n",
       "2 -0.269525  0.063426 -0.189034 -0.062240 -0.139962   -0.315248    0.0  \n",
       "3 -0.513540 -0.389335 -0.240228  0.047369  0.026852   -0.201302    0.0  \n",
       "4  0.072121  0.777835 -0.310421  0.021357  0.019546   -0.332959    0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Sampled Dataset/Random 50-50 Sampled Data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Whole dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_classifier= SVC(C= 1, kernel= 'rbf', random_state= 0)\n",
    "svm_classifier.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAADMCAYAAAA1fuKgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEQdJREFUeJzt3Xu4VfO+x/H3p1WpVRRSKHILJcrRjn1sIZ4kJ7f0UB1d\nHQfbYfO4bWwHj71dsu2KXCoRkntu1bE30s1KpaQorI1uaGVVUqu08T1/jFHNtVqX2VprrjH79X09\nz3yac8zfGOM75/r0m78x5phjyMxwLiS1ki7AuermoXbB8VC74HioXXA81C44HmoXHA/1DlLkCUlr\nJM2qwnJOkvRZddaWBEmPSvpT0nUUY2ZB3oAzgKnAj8AqYApwdjUs9yRgOdAg6ddYRn0HAQbMKzG9\nCbAZ+DrN5fQHpif9eipzC7KnlnQB8CLwFNACaAbcBnSvhsW3JArGhmpYViblSmqb8rg38FV1rkBS\nTnUur9ok/b8qAz2VgKXA9eW0qQXcCiwBCojC36hET9cvXs73wC3xc4OATcAvwHrgDkrp0eL5D4vv\ndwM+JfrEWAFcF08/BVieMk9r4D1gLfAJKZ8qwJPAcGBCvJwPgEPLeG1b6r8VGJwyfQ5wCyk9NXAT\n8M94mZ8C56XUkvo616bU8QgwEdgAnB5Puyt+/sa4ttrx48vj11KvRjOQdAgzEOoj4z/qweW0GQjk\nA4cADYFXgKdLhGIkUB9oB/wEtI6fLxbiNEL9LXBSfH9P4N9KhhqoE9dzM1AX6BwH7YiUMBUCHYHa\nwFjguQpCfRCwDMgB2gCL4xCmhronsD/Rf/IL46DuV87rehL4ATgxnqdeiVDXIhry3Q60AtYAx9Z0\nBkIcfuwd//ttOW36AA+Y2Zdmth74I3CRpNopbe4ws41mNh+YTxTuyvgX0EbSHma2xszmltLmBKL/\nXPeY2WYzexd4E+iV0ma8mc0ys5+JQt2+gvUuBz4jCnJf4OmSDczsRTP7xsx+NbPngS+I/uOU5zUz\nmxHPs6nE8n6N13UV8Dpwn5nNq2B51S6rQy2pj6T18W1SPG19yu3AeOt7y+ObiXo0gP3KWfT+REOP\nLZYQ9YDNUqZ9l3K/iCh0ldGDaAiyRNIUSb8to55lcShSa2pexXqeIupxe1FKqCX1lfSRpLWS1gJt\niTYoy7OsvCfN7GtgMtEnxfCUdRX7O8V7f7Y8/iRu80nKtJPSeH2lql1xk+SY2ViiXil1Wsk/5mXx\nDYh2uRG98T2A+8tY9DdEG3xbHAj8DKwk2rDcERuA3JT171ui3tnAOZLqAFcCLwAHlFLPAZJqpQT7\nQODzHaylpJeBh4APzWyppMNT6mxJNMQ6Dcgzs18kfUS0TQLREKY05R7WKeks4LfAO8Bg4L8BzKzY\n3ylW7G9pZkel86IqktU9dWVYNLi7FviTpAGS9pBUS9LvJI2Im40DrpF0sKSGwF+A5+OP9h01HzhK\nUntJ9YjGkwBIqht/2jQys38B64BfS1nGB0S97w2S6kg6hWhPzXOVqGcri/bQdAYuKeXpBkQBXRXX\nOoCop95iJdBCUt101yepCTAqXl8/oLukbpWrvvKCCzWAmb1EtOEzkKgXXAncBbwWNxlN9HE8lWg3\n1ybgfyq5rs+BO4G3icak00s0uRj4WtI6op6qTynL2EwU4jOJ9rY8DPQ1s8WVqanEsueY2T9Lmf4p\n8Fcgj+j9ORqYkdLkXaI9F99J+j7N1Y0gGnNPNLNCor1FoyTtXcF81UrxVqtzwQiyp3a7Ng+1C46H\n2gXHQ+2C46F2wfFQu+B4qF1wPNQuOB5qFxwPtQuOh9oFx0PtgpNVx1M3aryXNd2vecUNdxGNGuyW\ndAlZ4+MFC9Zt/umnRum0zapQN92vOUNHv5J0GVnjjONbJV1C1tinyV4F6bb14YcLjofaBcdD7YLj\noXbB8VC74HioXXA81C44HmoXHA+1C46H2gXHQ+2C46F2wfFQu+B4qF1wPNQuOB5qFxwPtQuOh9oF\nx0PtguOhdsHxULvgeKhdcDzULjgeahccD7ULjofaBcdD7YKzy4V6yJ//SO9uJ3BFn7O2Tnt6xBB+\nf3F3rux3NrdePYDCVSuLzVPw3Tf0OK09Lz/7eE2Xm6hhw4bS7pi2HHP0UQwdOiTpctKW0VBL6irp\nM0n5km7K5LrSdXq387nzb8XD2aPPJQx/+g0eGvM6HU88lXFPDC/2/Khhd3PcCZ1qsszELVy4kMdH\njSRv5izmzpvPhAlvkp+fn3RZaclYqCXlAMOJLiLfBuglqU2m1peutsf+ht33KH5G2NwGDbfe37Sp\nCElbH+dN+QfN9m9By4MPq7Eas8HiRYvo2PF4cnNzqV27Np06ncz48TvHGWkz2VN3BPLN7Esz2ww8\nB5yTwfVVyZhHH6DfuZ147603+M9LrgZgY9EGXnpmJL0HXplwdTXvqLZtmT59GoWFhRQVFTFp0kSW\nL1uWdFlpyWSomwOp78LyeFpW6nfZtYx5dSqnnNGdN15+GoCxjz/IuRf1p35ug4Srq3mtW7fm+utv\n5MyuXejWrSvt27UnJycn6bLSkviGoqRLJc2RNOeHNauTLodTupzN+5P/DsDnn85n9PDBDDj/VF57\nYQwvjHmUN156OuEKa87AQYOYNftD3ntvKo333JNWhx+edElpyeSVBFYAB6Q8bhFPK8bMRgAjAFq1\nPtoyWE+ZViz7muYHHATAzGlv06LlIQDc98i4rW3GjhpGvdwGdL/g4iRKTERBQQFNmzZl6dKlvDr+\nFWa8PzPpktKSyVDPBlpJOpgozBcBvTO4vrTce9s1LJg3i3Vr19D3nJPoc8lVzMmbwoolX6FatWi6\n7/78/oY7ki4zK/Ts2YPVhYXUqVOHYQ8Op3HjxkmXlBaZZa5zlNQNGALkAKPN7M/ltW/V+mjza75s\n49d82WafJnvlr169Oq03JKMXMjKzicDETK7DuZIS31B0rrp5qF1wPNQuOB5qFxwPtQuOh9oFx0Pt\nguOhdsHxULvgeKhdcDzULjgeahccD7ULjofaBcdD7YLjoXbBKfNHApLeAMr8WYyZnZ2RipyrovJ+\n+XJ/jVXhXDUqM9RmNqUmC3GuulT4G0VJrYC7iU4dVm/LdDM7JIN1OVdp6WwoPgE8AvwMnAo8BTyT\nyaKcq4p0Ql3fzN4hOp3CEjO7HTirgnmcS0w6p0j4SVIt4AtJVxKdmKZhBfM4l5h0euqrgVzgKuA4\n4GKgXyaLcq4qKuypzWx2fHc9MCCz5ThXdens/ZhMKV/CmFnnjFTkXBWlM6a+LuV+PaAH0Z4Q57JS\nOsOPD0tMmiFpVobqca7K0hl+7JXysBbRxmKjMpo7l7h0hh8fEo2pRTTs+AoYlIliGjXYzU9fm+Kt\n6QuSLiFrrFlXlHbbdELd2sw2pU6QtNuOFuVcTUlnP/X7pUzLq+5CnKsu5R1PvS/R1bTqSzqWaPgB\nsAfRlzHOZaXyhh9nAP2JLkD0V7aFeh1wc2bLcq7yyjueegwwRlIPM3u5BmtyrkrSGVMfJ2nrZZkk\n7SnprgzW5FyVpBPqM81s7ZYHZrYG6Ja5kpyrmnRCnZO6C09SfcB36bmslc5+6rHAO5KeINpY7A+M\nyWRRzlVFOsd+3CtpPnA60TeLbwEtM12Yc5WV7slsVhIFuifQGViUsYqcq6Lyvnw5HOgV374Hnif6\nneKpNVSbc5VS3vBjMTAN+A8zyweQdE2NVOVcFZQ3/Dgf+BaYLGmkpNPY9q2ic1mrzFCb2atmdhFw\nJDAZ+APQVNIjkrrUVIHO7agKNxTNbIOZPWtm3YmOA5kH3JjxypyrpB06la+ZrTGzEWZ2WqYKcq6q\n/PzULjgeahccD7ULjofaBcdD7YLjoXbB8VC74HioXXA81C44HmoXHA+1C46HOsWwYUNpd0xbjjn6\nKIYOHZJ0OTViyD230fuck7mi/3nbPffK82M46+Rj+GHtmmLTC1Z+S4+ux/Pyc0/WUJU7JmOhljRa\nUoGkhZlaR3VauHAhj48aSd7MWcydN58JE94kPz8/6bIy7vQzz+bOwY9sN31VwXfMm53HPs322+65\nUcMHc1zH39VEeZWSyZ76SaBrBpdfrRYvWkTHjseTm5tL7dq16dTpZMaPfyXpsjKubbsO7L779qcb\nH/nQfQy47Bqk4r8LyZv2Ls32a07Lgw+tqRJ3WMZCbWZTgdWZWn51O6ptW6ZPn0ZhYSFFRUVMmjSR\n5cuWJV1WIvKmT2bvJk055LAjik3fWFTES8+Opne/yxOqLD3pnPdjl9C6dWuuv/5GzuzahdwGDWjf\nrj05OTlJl1XjNm3ayAvPjOSu+x/b7rmxTz7MuT0vpn5udp/0NvFQS7oUuBTgwAMPTLSWgYMGMXBQ\ndJGEW265mRYtWiRaTxK+W7GMld+u4MpBPQH4ftVKrv6vC3ng0Wf5/NMFzJjyNqMf+xsb1v+IJOrW\n3Y3u5/dKuOriEg+1mY0ARgB06NBhu0vb1aSCggKaNm3K0qVLeXX8K8x4f2aS5STioEMP59nXpmx9\nPODCrgx5bByNGu/JfQ9tOzHX2Ccepl793KwLNGRBqLNJz549WF1YSJ06dRj24HAaN25c8Uw7uXvv\nuIEFH81h3Q9r6XvB6fQZcAVnnHV+0mVVicwy0zlKGgecAjQhOsPT/5rZ4+XN06FDB/tg1pyM1LMz\n8gsZbXNW59/k28+b0rrKVcZ6ajPLvs8lt0vwbxRdcDzULjgeahccD7ULjofaBcdD7YLjoXbB8VC7\n4HioXXA81C44HmoXHA+1C46H2gXHQ+2C46F2wfFQu+B4qF1wPNQuOB5qFxwPtQuOh9oFx0PtguOh\ndsHxULvgeKhdcDzULjgeahccD7ULjofaBSdjp/KtDEmrgCVJ10F0+uHvky4ii2TD+9HSzPZJp2FW\nhTpbSJpjZh2SriNb7Gzvhw8/XHA81C44HurSjUi6gCyzU70fPqZ2wfGe2gXHQ51CUldJn0nKl3RT\n0vUkSdJoSQWSFiZdy47yUMck5QDDgTOBNkAvSW2SrSpRTwJdky6iMjzU23QE8s3sSzPbDDwHnJNw\nTYkxs6nA6qTrqAwP9TbNgWUpj5fH09xOxkPtguOh3mYFcEDK4xbxNLeT8VBvMxtoJelgSXWBi4DX\nE67JVYKHOmZmPwNXAm8Bi4AXzOyTZKtKjqRxQB5whKTlkgYlXVO6/BtFFxzvqV1wPNQuOB5qFxwP\ntQuOh9oFx0NdRZJ+kfSRpIWSXpSUW4VlnSLpzfj+2eUdKSipsaQrKrGO2yVdV9kadwYe6qrbaGbt\nzawtsBm4LPVJRXb4fTaz183snnKaNAZ2ONS7Ag919ZoGHCbpoPi47KeAhcABkrpIypM0N+7RG8LW\nY7gXS5oLnL9lQZL6S3oovt9M0nhJ8+PbvwP3AIfGnxKD43bXS5ot6WNJd6Qs6xZJn0uaDhxRY+9G\nQmonXUAoJNUmOhb7/+JJrYB+ZjZTUhPgVuB0M9sg6UbgWkn3ASOBzkA+8HwZix8GTDGz8+LjvhsC\nNwFtzax9vP4u8To7AgJel9QJ2ED0lX97or/3XODD6n312cVDXXX1JX0U358GPA7sDywxs5nx9BOI\nfngwQxJAXaKvoI8EvjKzLwAkPQNcWso6OgN9AczsF+AHSXuWaNMlvs2LHzckCvnuwHgzK4rXEfzx\nLB7qqtu4pbfcIg7uhtRJwD/MrFeJdsXmqyIBd5vZYyXW8YdqXMdOwcfUNWMmcKKkwwAkNZB0OLAY\nOEjSoXG7XmXM/w5weTxvjqRGwI9EvfAWbwEDU8bqzSU1BaYC50qqL2l3oHs1v7as46GuAWa2CugP\njJP0MfHQw8w2EQ03JsQbigVlLOJq4FRJC4jGw23MrJBoOLNQ0mAz+zvwLJAXt3sJ2N3M5hKN1ecD\nk4gOsQ2aH6XnguM9tQuOh9oFx0PtguOhdsHxULvgeKhdcDzULjgeahec/wfoehAhhVrbGQAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85ad3780b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive= 134 , True Negetive= 144 , False Positive= 9 , False Negetive= 9 \n",
      "\n",
      "The accuracy is 93.9189189189 %\n",
      "The recall is 93.7062937063 %\n",
      "The precision is 93.7062937063 %\n",
      "The F1 Score is 93.7062937063 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "def confusion_matrix_1(CM):\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=CM)\n",
    "    plt.title(\"---Confusion Matrix---\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.show()\n",
    "    \n",
    "    TP=CM[0,0]\n",
    "    FN=CM[0,1]\n",
    "    FP=CM[1,0]\n",
    "    TN=CM[1,1]\n",
    "    \n",
    "    print(\"True Positive=\",TP,\", True Negetive=\",TN,\", False Positive=\",FP,\", False Negetive=\",FN,\"\\n\")\n",
    "    \n",
    "    accuracy=(TP+TN)/(TP+FP+FN+TN)\n",
    "    recall=TP/(TP+FN)\n",
    "    precision=TP/(TP+FP)\n",
    "    f1=(2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    print(\"The accuracy is \"+str(accuracy*100) + \" %\")\n",
    "    print(\"The recall is \"+ str(recall*100) +\" %\")\n",
    "    print(\"The precision is \"+ str(precision*100) +\" %\")\n",
    "    print(\"The F1 Score is \"+ str(f1*100) +\" %\")\n",
    "        \n",
    "confusion_matrix_1(cm1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
