{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normAmount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-13.086519</td>\n",
       "      <td>7.352148</td>\n",
       "      <td>-18.256576</td>\n",
       "      <td>10.648505</td>\n",
       "      <td>-11.731476</td>\n",
       "      <td>-3.659167</td>\n",
       "      <td>-14.873658</td>\n",
       "      <td>8.810473</td>\n",
       "      <td>-5.418204</td>\n",
       "      <td>-13.202577</td>\n",
       "      <td>...</td>\n",
       "      <td>2.761157</td>\n",
       "      <td>-0.266162</td>\n",
       "      <td>-0.412861</td>\n",
       "      <td>0.519952</td>\n",
       "      <td>-0.743909</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>-2.498300</td>\n",
       "      <td>-0.711066</td>\n",
       "      <td>-0.305610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775570</td>\n",
       "      <td>-0.770648</td>\n",
       "      <td>0.936321</td>\n",
       "      <td>1.312951</td>\n",
       "      <td>-1.060369</td>\n",
       "      <td>0.343982</td>\n",
       "      <td>-0.509566</td>\n",
       "      <td>0.281372</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>-0.081314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064923</td>\n",
       "      <td>-0.121614</td>\n",
       "      <td>-0.206049</td>\n",
       "      <td>-0.029554</td>\n",
       "      <td>0.318518</td>\n",
       "      <td>-0.420916</td>\n",
       "      <td>0.025195</td>\n",
       "      <td>0.054102</td>\n",
       "      <td>0.307804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.098257</td>\n",
       "      <td>0.277438</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.541734</td>\n",
       "      <td>0.744008</td>\n",
       "      <td>0.239270</td>\n",
       "      <td>0.852291</td>\n",
       "      <td>-0.130182</td>\n",
       "      <td>0.684496</td>\n",
       "      <td>-0.425860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382471</td>\n",
       "      <td>1.551722</td>\n",
       "      <td>-0.164158</td>\n",
       "      <td>0.716621</td>\n",
       "      <td>-0.432961</td>\n",
       "      <td>-0.479633</td>\n",
       "      <td>0.110424</td>\n",
       "      <td>0.034605</td>\n",
       "      <td>-0.235720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.093755</td>\n",
       "      <td>0.557129</td>\n",
       "      <td>1.603202</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>1.060342</td>\n",
       "      <td>0.071394</td>\n",
       "      <td>0.476971</td>\n",
       "      <td>0.216907</td>\n",
       "      <td>-0.400491</td>\n",
       "      <td>-0.607183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046997</td>\n",
       "      <td>-0.050579</td>\n",
       "      <td>-0.460900</td>\n",
       "      <td>-0.290351</td>\n",
       "      <td>0.782954</td>\n",
       "      <td>-0.449391</td>\n",
       "      <td>-0.104006</td>\n",
       "      <td>-0.067875</td>\n",
       "      <td>-0.415446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.369120</td>\n",
       "      <td>1.099830</td>\n",
       "      <td>1.393934</td>\n",
       "      <td>-0.638975</td>\n",
       "      <td>-0.588518</td>\n",
       "      <td>0.260273</td>\n",
       "      <td>0.216639</td>\n",
       "      <td>0.545081</td>\n",
       "      <td>-0.049583</td>\n",
       "      <td>-0.726512</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043952</td>\n",
       "      <td>-0.411460</td>\n",
       "      <td>-0.199765</td>\n",
       "      <td>-0.463215</td>\n",
       "      <td>0.240325</td>\n",
       "      <td>-0.432551</td>\n",
       "      <td>-0.427597</td>\n",
       "      <td>-0.019662</td>\n",
       "      <td>-0.176961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1        V2         V3         V4         V5        V6         V7  \\\n",
       "0 -13.086519  7.352148 -18.256576  10.648505 -11.731476 -3.659167 -14.873658   \n",
       "1   0.775570 -0.770648   0.936321   1.312951  -1.060369  0.343982  -0.509566   \n",
       "2  -0.098257  0.277438   0.682605   0.541734   0.744008  0.239270   0.852291   \n",
       "3  -1.093755  0.557129   1.603202   0.008525   1.060342  0.071394   0.476971   \n",
       "4  -1.369120  1.099830   1.393934  -0.638975  -0.588518  0.260273   0.216639   \n",
       "\n",
       "         V8        V9        V10  ...         V21       V22       V23  \\\n",
       "0  8.810473 -5.418204 -13.202577  ...    2.761157 -0.266162 -0.412861   \n",
       "1  0.281372  0.823800  -0.081314  ...    0.064923 -0.121614 -0.206049   \n",
       "2 -0.130182  0.684496  -0.425860  ...    0.382471  1.551722 -0.164158   \n",
       "3  0.216907 -0.400491  -0.607183  ...   -0.046997 -0.050579 -0.460900   \n",
       "4  0.545081 -0.049583  -0.726512  ...   -0.043952 -0.411460 -0.199765   \n",
       "\n",
       "        V24       V25       V26       V27       V28  normAmount  Class  \n",
       "0  0.519952 -0.743909 -0.167808 -2.498300 -0.711066   -0.305610      1  \n",
       "1 -0.029554  0.318518 -0.420916  0.025195  0.054102    0.307804      0  \n",
       "2  0.716621 -0.432961 -0.479633  0.110424  0.034605   -0.235720      0  \n",
       "3 -0.290351  0.782954 -0.449391 -0.104006 -0.067875   -0.415446      0  \n",
       "4 -0.463215  0.240325 -0.432551 -0.427597 -0.019662   -0.176961      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Sampled Dataset/Without Kmeans 50-50 Sampled.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data.loc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Whole dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_classifier= SVC(C= 1, kernel= 'rbf', random_state= 0)\n",
    "svm_classifier.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAADMCAYAAAA1fuKgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noXbB8VC74PwbAhEkc9IeceAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f527626fcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive= 132 , True Negetive= 144 , False Positive= 12 , False Negetive= 8 \n",
      "\n",
      "The accuracy is 93.2432432432 %\n",
      "The recall is 94.2857142857 %\n",
      "The precision is 91.6666666667 %\n",
      "The F1 Score is 92.9577464789 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "def confusion_matrix_1(CM):\n",
    "    fig, ax = plot_confusion_matrix(conf_mat=CM)\n",
    "    plt.title(\"---Confusion Matrix---\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.show()\n",
    "    \n",
    "    TP=CM[0,0]\n",
    "    FN=CM[0,1]\n",
    "    FP=CM[1,0]\n",
    "    TN=CM[1,1]\n",
    "    \n",
    "    print(\"True Positive=\",TP,\", True Negetive=\",TN,\", False Positive=\",FP,\", False Negetive=\",FN,\"\\n\")\n",
    "    \n",
    "    accuracy=(TP+TN)/(TP+FP+FN+TN)\n",
    "    recall=TP/(TP+FN)\n",
    "    precision=TP/(TP+FP)\n",
    "    f1=(2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    print(\"The accuracy is \"+str(accuracy*100) + \" %\")\n",
    "    print(\"The recall is \"+ str(recall*100) +\" %\")\n",
    "    print(\"The precision is \"+ str(precision*100) +\" %\")\n",
    "    print(\"The F1 Score is \"+ str(f1*100) +\" %\")\n",
    "        \n",
    "confusion_matrix_1(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
